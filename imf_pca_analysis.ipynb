{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5119cf-3278-4e9d-a7fd-e93e63905afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directories\n",
    "input_dir = os.path.join(os.getcwd(), \"IMF_data_by_countries\")\n",
    "output_dir = os.path.join(os.getcwd(), \"IMF_data_by_countries_after_processing\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Ignore sheets\n",
    "ignore_sheets = {\"missing_indicators\", \"IMF_Indicators\"}\n",
    "\n",
    "# Indicator groups\n",
    "households = [\"S14\", \"S15\"]\n",
    "financials = [\"S12\"]\n",
    "nonfinancials = [\"S11\"]\n",
    "\n",
    "def cdf_transform(series):\n",
    "    \"\"\"Applies a rank-based (CDF) transformation.\"\"\"\n",
    "    ranks = rankdata(series)\n",
    "    return ranks / (len(ranks) + 1)\n",
    "\n",
    "def process_country(file_name):\n",
    "    if not file_name.endswith(\".xlsx\"):\n",
    "        return\n",
    "    \n",
    "    country_name = file_name.replace(\".xlsx\", \"\")\n",
    "    file_path = os.path.join(input_dir, file_name)\n",
    "    print(f\"Processing {country_name}...\")\n",
    "    \n",
    "    try:\n",
    "        xls = pd.ExcelFile(file_path)\n",
    "        sheets = xls.sheet_names\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_name}: {e}\")\n",
    "        return\n",
    "    \n",
    "    indicator_sheets = [sheet for sheet in sheets if sheet not in ignore_sheets]\n",
    "    if not indicator_sheets:\n",
    "        print(f\"No valid indicator sheets found for {country_name}. Skipping...\")\n",
    "        return\n",
    "    \n",
    "    data = {}\n",
    "    for sheet in indicator_sheets:\n",
    "        try:\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "            if 'date' not in df.columns or 'value' not in df.columns:\n",
    "                continue\n",
    "            df = df[['date', 'value']].rename(columns={'value': sheet})\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            df.sort_values('date', inplace=True)\n",
    "            data[sheet] = df\n",
    "        except Exception as e:\n",
    "            print(f\"Error in sheet '{sheet}' for {country_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not data:\n",
    "        print(f\"No valid data for {country_name}. Skipping...\")\n",
    "        return\n",
    "    \n",
    "    # Merge data by date\n",
    "    merged_data = None\n",
    "    for sheet, df in data.items():\n",
    "        if merged_data is None:\n",
    "            merged_data = df\n",
    "        else:\n",
    "            merged_data = pd.merge(merged_data, df, on='date', how='outer')\n",
    "    \n",
    "    merged_data.set_index('date', inplace=True)\n",
    "    numeric_cols = merged_data.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # Apply CDF transformation\n",
    "    for col in numeric_cols:\n",
    "        merged_data[col] = cdf_transform(merged_data[col])\n",
    "    \n",
    "    # Subsetting into categories\n",
    "    household_data = merged_data[[col for col in numeric_cols if any(h in col for h in households)]]\n",
    "    financial_data = merged_data[[col for col in numeric_cols if any(f in col for f in financials)]]\n",
    "    nonfinancial_data = merged_data[[col for col in numeric_cols if any(n in col for n in nonfinancials)]]\n",
    "    \n",
    "    # Apply PCA per subset\n",
    "    for subset_name, subset_data in zip([\n",
    "        \"Households\", \"Financials\", \"Non-Financials\"],\n",
    "        [household_data, financial_data, nonfinancial_data]):\n",
    "        \n",
    "        if subset_data.empty:\n",
    "            continue\n",
    "        \n",
    "        subset_data.fillna(subset_data.mean(), inplace=True)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(subset_data)\n",
    "        \n",
    "        pca = PCA()\n",
    "        pca.fit(scaled_data)\n",
    "        eigenvalues = pca.explained_variance_\n",
    "        selected_components = [i+1 for i, val in enumerate(eigenvalues) if val > 1]\n",
    "        \n",
    "        if not selected_components:\n",
    "            continue\n",
    "        \n",
    "        pca = PCA(n_components=len(selected_components))\n",
    "        scores = pca.fit_transform(scaled_data)\n",
    "        loadings = pca.components_\n",
    "        \n",
    "        output_path = os.path.join(output_dir, country_name, subset_name)\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        \n",
    "        # Save PCA results\n",
    "        scores_df = pd.DataFrame(scores, columns=[f\"PC{i}\" for i in range(1, len(selected_components)+1)], index=subset_data.index)\n",
    "        scores_df.to_csv(os.path.join(output_path, \"pca_scores.csv\"))\n",
    "        \n",
    "        loadings_df = pd.DataFrame(loadings, columns=subset_data.columns, index=[f\"PC{i}\" for i in range(1, len(selected_components)+1)]).T\n",
    "        loadings_df.to_csv(os.path.join(output_path, \"pca_loadings.csv\"))\n",
    "        \n",
    "        # Save PCA summary\n",
    "        with open(os.path.join(output_path, \"PCA_summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"PCA Summary for {country_name} - {subset_name}\\n\")\n",
    "            f.write(\"=\"*40 + \"\\n\\n\")\n",
    "            f.write(\"Eigenvalues:\\n\")\n",
    "            for i, val in enumerate(eigenvalues, start=1):\n",
    "                f.write(f\"PC{i}: {val:.4f}\\n\")\n",
    "            f.write(\"\\nComponents retained (Kaiser Rule):\\n\")\n",
    "            f.write(f\"{selected_components}\\n\")\n",
    "            f.write(f\"Number of components retained: {len(selected_components)}\\n\\n\")\n",
    "            f.write(\"Explained Variance Ratio:\\n\")\n",
    "            for i, ratio in enumerate(pca.explained_variance_ratio_, start=1):\n",
    "                f.write(f\"PC{i}: {ratio*100:.2f}%\\n\")\n",
    "    \n",
    "    print(f\"Processing completed for {country_name}.\")\n",
    "\n",
    "# Process all files\n",
    "for file_name in os.listdir(input_dir):\n",
    "    process_country(file_name)\n",
    "\n",
    "print(\"All countries processed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
